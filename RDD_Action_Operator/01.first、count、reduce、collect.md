## RDDAction操作(1)–first、count、reduce、collect
### 算子
算子是一个函数空间到函数空间上的映射O: X -> X。

广义上的算子可以推广到任何空间，如内积空间等。

### first
def first(): T

first返回RDD中的第一个元素，不排序

```
scala> var rdd1 = sc.makeRDD(Array(("a",1),("b",2),("c",3),4))
rdd1: org.apache.spark.rdd.RDD[Any] = ParallelCollectionRDD[0] at makeRDD at <console>:27

scala> rdd1.first
res0: Any = (a,1)

var rdd1 = sc.makeRDD(Seq(10, 4, 2, 12, 3))
rdd1: org.apache.spark.rdd.RDD[Int] = ParallelCollectionRDD[1] at makeRDD at <console>:27

scala> rdd1.first
res1: Int = 10
```

### count
def count(): Long

count返回RDD中元素数量

```
scala> var rdd1 = sc.makeRDD(Array(("A","1"),("B","2"),("C","3")),2)
rdd1: org.apache.spark.rdd.RDD[(String, String)] = ParallelCollectionRDD[34] at makeRDD at :21

scala> rdd1.count
res15: Long = 3
```

### reduce
def reduce(f: (T, T) ⇒ T): T

根据映射函数f，对RDD中的元素进行二元计算，返回计算结果。

```
scala> var rdd1 = sc.makeRDD(1 to 10,2)
rdd1: org.apache.spark.rdd.RDD[Int] = ParallelCollectionRDD[36] at makeRDD at :21

scala> rdd1.reduce(_ + _)
res18: Int = 55

scala> var rdd2 = sc.makeRDD(Array(("A",0),("A",2),("B",1),("B",2),("C",1)))
rdd2: org.apache.spark.rdd.RDD[(String, Int)] = ParallelCollectionRDD[38] at makeRDD at :21

scala> rdd2.reduce((x,y) => {
     |       (x._1 + y._1,x._2 + y._2)
     |     })
res21: (String, Int) = (CBBAA,6)

```

### collect
def collect(): Array[T]

collect用于将一个RDD转换为数组

```
scala> var rdd1 = sc.makeRDD(1 to 10,2)
rdd1: org.apache.spark.rdd.RDD[Int] = ParallelCollectionRDD[36] at makeRDD at :212

```

